{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ne0MSWVtQKs_",
        "Dyz8RUUfQ-mc",
        "HGYnki5JRU9i",
        "KXF_EPoUSIAi"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syh4bPRREr33"
      },
      "source": [
        "## p  y  t  h  o  n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne0MSWVtQKs_"
      },
      "source": [
        "## *l i b r a r i e s*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43sjzGqJYOIs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "34ed464e-f661-4bdb-ca96-42bcfa6684b0"
      },
      "source": [
        "# ---- basics / misc ---- #\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn import set_config\n",
        "import requests\n",
        "import time\n",
        "import statsmodels.api as sm\n",
        "from ipywidgets import interact\n",
        "import scipy as sp\n",
        "# ---- pre-processing / featurization ---- #\n",
        "from sklearn.compose import make_column_transformer, make_column_selector\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from category_encoders import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV\n",
        "# ---- word things ----\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from textblob import TextBlob\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from bs4 import BeautifulSoup\n",
        "# ---- modeling ---- #\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, SGDClassifier, SGDRegressor,\n",
        "                                 LogisticRegression, LassoLARS, LogisticRegressionCV\n",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, AdaBoostClassifier,\n",
        "                             AdaBoostRegressor, GradientBoostingClassifier, GradientBoostingRegressor,\n",
        "                             HistGradientBoostingClassifier, HistGradientBoostingRegressor,\n",
        "                             VotingClassifier, VotingRegressor\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
        "# ---- evaluation ---- #\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score,\n",
        "                            precision_score, recall_score, roc_auc_score,\n",
        "                            mean_squared_error, mean_absolute_error, r2_score,\n",
        "                            plot_confusion_matrix, classification_report, plot_roc_curve, f1_score\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "from scipy import stats\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from plotter import SVMPlotter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-c29ae3bf21d5>\"\u001b[0;36m, line \u001b[0;32m37\u001b[0m\n\u001b[0;31m    LogisticRegression, LassoLARS, LogisticRegressionCV\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dyz8RUUfQ-mc"
      },
      "source": [
        "## *v i s u a l i z a t i o n s*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3TTnuY_cduJ"
      },
      "source": [
        "#visualize the correlations\n",
        "                           #with a pretty heatmap\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "mask = np.zeros_like(df.corr())\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "plt.figure(figsize=(18, 5))\n",
        "sns.heatmap(\n",
        "    df.corr(),\n",
        "    cmap='coolwarm',\n",
        "    annot=True,\n",
        "    mask=mask,\n",
        "    vmin=-1.,\n",
        "    vmax=1.,\n",
        "    linewidths=.01\n",
        ")\n",
        "plt.title('Correlation matrix');\n",
        "\n",
        "#doing a heatmap with only one thing on bottom vs your features on the y\n",
        "sns.heatmap(df.corr()[['target']],\n",
        "            annot = True,\n",
        "            cmap='coolwarm',\n",
        "            vmin=-1.,\n",
        "            vmax=1.,\n",
        "            linewidths=.01\n",
        ").set_title('Correlation matrix'); #this one is clutch for making new features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lxiaL4Q67qv"
      },
      "source": [
        "#making a histogram for all features pertaining to finding corr type info in logistic regression\n",
        "fig, ax = plt.subplots(10, 3, figsize = (20, 20))\n",
        "features = feature_df.columns\n",
        "feature_counter = 0\n",
        "for row in range(10):\n",
        "    for col in range(3):\n",
        "        feature = features[feature_counter]\n",
        "        malig = cancer_df.loc[cancer_df['malignant'] == 1][feature]\n",
        "        non = cancer_df.loc[cancer_df['malignant'] == 0][feature]\n",
        "        ax[row, col].hist(malig, alpha = 0.4)\n",
        "        ax[row, col].hist(non, alpha = 0.4)\n",
        "        ax[row, col].set_title(feature)\n",
        "        feature_counter += 1\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlhLpLm29dMS"
      },
      "source": [
        "#subplots without overlap\n",
        "fig, ax = plt.subplots(3, 2, figsize = (18,12))\n",
        "sns.cubehelix_palette(as_cmap=True)\n",
        "sns.distplot(df['sEXT'], ax = ax[0,0]).set_title(\"Distribution of sEXT\");\n",
        "sns.distplot(df['sNEU'], ax = ax[0,1]).set_title(\"Distribution of sNEU\");\n",
        "sns.distplot(df['sAGR'], ax = ax[1,0]).set_title(\"Distribution of sAGR\");\n",
        "sns.distplot(df['sCON'], ax = ax[1,1]).set_title(\"Distribution of sCON\");\n",
        "sns.distplot(df['sOPN'], ax = ax[2,0]).set_title(\"Distribution of sOPN\");\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeQ2O5I_ZJs6"
      },
      "source": [
        "#cool overlapping histogram\n",
        "for group in cancer_df.groupby('malignant')['mean radius']:\n",
        "    sns.histplot(group[1]);\n",
        "plt.title('Mean Radius by Malignant Category');\n",
        "\n",
        "#lots of overlapping distplots\n",
        "fig, ax = plt.subplots(10, 3, figsize = (20, 20))\n",
        "features = feature_df.columns\n",
        "feature_counter = 0\n",
        "for row in range(10):\n",
        "    for col in range(3):\n",
        "        feature = features[feature_counter]\n",
        "        malig = cancer_df.loc[cancer_df['malignant'] == 1][feature]\n",
        "        non = cancer_df.loc[cancer_df['malignant'] == 0][feature]\n",
        "        ax[row, col].hist(malig, alpha = 0.4)\n",
        "        ax[row, col].hist(non, alpha = 0.4)\n",
        "        ax[row, col].set_title(feature)\n",
        "        feature_counter += 1\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlUgUA-sbe7K"
      },
      "source": [
        "#plots with overlap; also lazy filtering\n",
        "df_y = df[df.cNEU == 'y']\n",
        "df_n = df[df.cNEU == 'n']\n",
        "sns.distplot(df_y['status_word_count']);\n",
        "sns.distplot(df_n['status_word_count']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47BKL3RTRJls"
      },
      "source": [
        "#plt.plots next to each other\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20,6))\n",
        "\n",
        "ax1.plot(history.history['mae'], label = 'Train MAE')\n",
        "ax1.plot(history.history['val_mae'], label = 'Validation MAE')\n",
        "ax1.legend();\n",
        "\n",
        "ax2.plot(history.history['loss'], label = 'Train loss')\n",
        "ax2.plot(history.history['val_loss'], label = 'Validation loss')\n",
        "ax2.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPCBX7GDGsIP"
      },
      "source": [
        "#interactive plots\n",
        "import plotly.express as px\n",
        "fig = px.line(x=range(2, 10), y=silh_score, width=700, height=400)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9r35ea6Ozfw"
      },
      "source": [
        "#nice scattery boy? better ones out there\n",
        "plt.figure(figsize=(12,12))\n",
        "sns.scatterplot(x = wine_df['flavanoids'] , y = wine_df['total_phenols'],\n",
        "                hue = wine_df['wine_clusters'], size = wine_df['color_intensity'],\n",
        "                sizes = (30, 400));\n",
        "#or\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.scatterplot(df_train['SalePrice'], df_train['Overall Qual'],\n",
        "                hue = df_train['Overall Qual'],\n",
        "                size = df_train['Overall Qual'],\n",
        "                palette='flare').set_title(\"Sale Price in USD vs Overal Quality\");\n",
        "sns.set(style='darkgrid')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufqUkk8EGu4N"
      },
      "source": [
        "#chloroplethings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrrkY42KMf9b"
      },
      "source": [
        "#pairgrid\n",
        "sns.set(style=\"darkgrid\", context=\"notebook\")\n",
        "i = sns.PairGrid(X)\n",
        "i = i.map_lower(sns.regplot)\n",
        "i = i.map_upper(sns.kdeplot, cmap=\"Blues\", shade=True, shade_lowest=False)\n",
        "i = i.map_diag(plt.hist)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNQ3AZU2ffNd"
      },
      "source": [
        "#lots of overlapping bars; good for the subplot set-up\n",
        "digits = list(range(1, 10))\n",
        "benford = [np.log10(1 + (1/i)) for i in digits]\n",
        "\n",
        "checks_by_dept = df['DEPT_NM'].value_counts()\n",
        "large_depts = checks_by_dept[checks_by_dept >= 1000].index\n",
        "\n",
        "fix, axes = plt.subplots(nrows = len(large_depts), figsize = (10, 5*len(large_depts)))\n",
        "\n",
        "for i, dept in enumerate(large_depts):\n",
        "    dept_checks = df.loc[df['DEPT_NM'] == dept, 'FIRST_DIGIT'].value_counts(normalize = True).sort_values()\n",
        "    axes[i].bar(digits, benford, label = 'Expected')\n",
        "    axes[i].plot(dept_checks, color = 'r')\n",
        "    axes[i].set_title(dept);\n",
        "    i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGYnki5JRU9i"
      },
      "source": [
        "## *e v a l u a t i o n s*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb-opXMb85iy"
      },
      "source": [
        "#t test\n",
        "from scipy import stats\n",
        "\n",
        "x_m = df[df['gender']==1]['trip_duration']\n",
        "x_y = df[df['gender']==2]['trip_duration']\n",
        "\n",
        "stats.ttest_ind(x_m, x_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4Y73abKOqQG"
      },
      "source": [
        "#returning top words\n",
        "def top_words(X, vect):\n",
        "    dtm = pd.DataFrame(X.toarray(), columns = vect.get_feature_names())\n",
        "    return dtm.sum().sort_values(ascending = False).head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaE-ZZUJUFqR"
      },
      "source": [
        "#see all of your params for grid\n",
        "pipe.get_params().keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGFWHy6GTFBg"
      },
      "source": [
        "# separate these out !\n",
        "\n",
        "# null model\n",
        "print(f'Null model accuracy: {round(max(y_test.mean(), 1 - y_test.mean()), 2)}')\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "y_pred_test = lr.predict(X_test_encoded)\n",
        "y_true_test = y_test #?\n",
        "\n",
        "def classification_eval(y_test, y_pred):\n",
        "    print(f'accuracy  = {np.round(accuracy_score(y_test, y_pred), 3)}')\n",
        "    print(f'precision = {np.round(precision_score(y_test, y_pred), 3)}')\n",
        "    print(f'recall    = {np.round(recall_score(y_test, y_pred), 3)}')\n",
        "    print(f'f1-score  = {np.round(f1_score(y_test, y_pred), 3)}')\n",
        "    print(f'roc auc   = {np.round(roc_auc_score(y_test, y_pred), 3)}')\n",
        "    print(f'Null model accuracy: {round(max(y_test.mean(), 1 - y_test.mean()), 2)}')\n",
        "classification_eval(y_test, y_pred)\n",
        "\n",
        "def regression_eval(y_test, y_pred):\n",
        "    print(f'MSE = {np.round(mean_squared_error(y_test, y_pred), 3)}')\n",
        "    print(f'RMSE = {np.round(mean_squared_error(y_test, y_pred, squared = False), 3)}')\n",
        "    print(f'MAE = {np.round(mean_absolute_error(y_test, y_pred), 3)}')\n",
        "    print(f'r^2  = {np.round(r2_score(y_test, y_pred), 3)}')\n",
        "\n",
        "regression_eval(y_test, y_pred)\n",
        "\n",
        "# got some boxes idk\n",
        "def regression_and_eval(X, y):\n",
        "    #X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "    lr.fit(X, y)\n",
        "    y_pred = lr.predict(X)\n",
        "    print(' ______________ ')\n",
        "    print(f'| MSE  = {np.round(mean_squared_error(y, y_pred), 3)} |')\n",
        "    print('|--------------|')\n",
        "    print(f'| RMSE = {np.round(mean_squared_error(y, y_pred, squared = False), 3)} |')\n",
        "    print('|--------------|')\n",
        "    print(f'| MAE  = {np.round(mean_absolute_error(y, y_pred), 3)} |')\n",
        "    print('|--------------|')\n",
        "    print(f'| r^2  = {np.round(r2_score(y, y_pred), 3)} |')\n",
        "    print(' -------------- ')\n",
        "\n",
        "#compare to mean value MSE\n",
        "null_y = np.full_like(y_train, y.mean())\n",
        "mean_squared_error(y_train, null_y)\n",
        "\n",
        "# RMSE for test set\n",
        "mean_squared_error(y_test, y_pred_test, squared = False)\n",
        "\n",
        "# from brandon to organize\n",
        "# ---- df of best coefs / how to merge keeping the index ----\n",
        "features = pipe.named_steps.countvectorizer.get_feature_names()\n",
        "coefs = pipe.named_steps.logisticregression.coef_\n",
        "coefs_df = pd.DataFrame({'coefs': coefs[0]}, index = features)\n",
        "coefs_df.sort_values('coefs', ascending=False).head(30)\n",
        "\n",
        "# ---- print scores ----\n",
        "def print_scores(model):\n",
        "    print(f'train score: {round(model.score(X_train, y_train),2)}')\n",
        "    print(f'test score: {round(model.score(X_test, y_test),2)}')\n",
        "\n",
        "# ---- Getting feature importances ----\n",
        "def get_imports(pipe, estimator):\n",
        "    features = pipe.named_steps.countvectorizer.get_feature_names()\n",
        "    coefs = pipe.named_steps[estimator].coef_\n",
        "    coefs_df = pd.DataFrame({'coefs': coefs[0]}, index = features)\n",
        "    return coefs_df.sort_values('coefs', ascending=False).head(20)\n",
        "\n",
        "# ---- balanced accuracy ------\n",
        "test = pd.read_csv('./data/covid_tweets/Corona_NLP_train.csv', encoding='latin1')\n",
        "X_TEST = test['OriginalTweet']\n",
        "y_TEST = test['Sentiment']\n",
        "preds = logreg_grid.predict(X_TEST)\n",
        "logreg_grid.score(X_TEST, y_TEST)\n",
        "balanced_accuracy_score(y_TEST, preds)\n",
        "\n",
        "#---- outputting to csv ----- see index things above\n",
        "preds_array = np.full_like(df_test['Id'], y_pred)\n",
        "df_preds = pd.DataFrame(preds_array, columns = ['SalePrice'])\n",
        "df_pred = pd.concat([df_test['Id'], df_pred_sale_price_15], axis = 1)\n",
        "df_pred\n",
        "df_pred.to_csv('pred_submission.csv')\n",
        "\n",
        "#dataframe of / plot of importances after a tree\n",
        "pd.DataFrame({'importance' : gboost.feature_importances_,\n",
        "              'features' : cali.feature_names}).sort_values(by = 'importance')\n",
        "pd.DataFrame({'importance' : gboost.feature_importances_},\n",
        "              index = cali.feature_names).sort_values(by = 'importance').plot(kind = 'barh');\n",
        "\n",
        "\n",
        "# used this for comparing two diff preprocessing\n",
        "# comparing MSE for performance\n",
        "null_y = np.full_like(y_train, y.mean())\n",
        "\n",
        "null_MSE = np.round(mean_squared_error(y_train, null_y), 3)\n",
        "MSE = np.round(mean_squared_error(y_test, y_pred), 3)\n",
        "\n",
        "print(f'Percent improvement = {(np.abs(np.round(((null_MSE - MSE) / null_MSE), 3)))*100}%')\n",
        "\n",
        "#plotting probabilities\n",
        "y_pred_prob = grid.predict_proba(X_test)\n",
        "sns.distplot(y_pred_prob[:, 1]);\n",
        "plt.title('Histogram of predicted probabilities');\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXF_EPoUSIAi"
      },
      "source": [
        "# *m o d e l i n g  /  f u n c t i o n s*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXoY3hqFVrgK"
      },
      "source": [
        "pre-processing / featurization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVqcd1LSTE5n"
      },
      "source": [
        "#test every possible feature combination??\n",
        "from itertools import combinations\n",
        "features = X.columns\n",
        "[list(combinations(features, i)) for i in range(len(features))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6qZsIlhVzDH"
      },
      "source": [
        "# ---- pre-processing function ---- #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ab7E21KRqoS"
      },
      "source": [
        "`regression`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmNLSpOtNtEM"
      },
      "source": [
        "#statsmodel regression => needs verification of below\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "\n",
        "X = df.your stuff\n",
        "y = df.your other stuff\n",
        "X = sm.add_constant(X)\n",
        "lr = sm.OLS(X, y)\n",
        "model = lr.fit()\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7t_I1Zg067S1"
      },
      "source": [
        "#another quick regression\n",
        "result = scipy.stats.linregress(x, y) #x, and y may be switched depending on which are features vs obs\n",
        "                                      #might need to transpose via .T first\n",
        "result.slope\n",
        "result.intercept\n",
        "result.rvalue\n",
        "result.pvalue\n",
        "result.stderr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWYmotpEPeic"
      },
      "source": [
        "# ---- regression function ---- #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpAO_BgMR1r3"
      },
      "source": [
        "classification\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypXunYHSPfFt"
      },
      "source": [
        "# ---- classification function ---- #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK6vg1CbfGMs"
      },
      "source": [
        "#K-Means & DBSCAN\n",
        " # remember to add a column of labels to your dataframe\n",
        "#K-means testing:\n",
        "for k in range(1, 10):\n",
        "    kmeans = KMeans(n_clusters = k, random_state = 123)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "inertia\n",
        "\n",
        "for i in range(2, 15):\n",
        "    kmeans = KMeans(n_clusters = i, random_state = 123)\n",
        "    kmeans.fit(X_scaled)\n",
        "    silh_score.append(silhouette_score(X_scaled, kmeans.labels_))\n",
        "\n",
        "import plotly.express as px\n",
        "fig = px.line(x=range(2, 15), y=silh_score, width=700, height=400)\n",
        "fig.show()\n",
        "\n",
        "#DBSCAN function\n",
        "def find_best_silhouette(df):\n",
        "    \"\"\"select best eps and min_samples for a DBSCAN\n",
        "    Args:\n",
        "        df (pandas DataFrame): data to cluster\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    rows = df.shape[0]\n",
        "    eps_vals = np.linspace(.2, 5, 50)\n",
        "    samp_vals = range(2, rows // 2 + 1)\n",
        "    scores = np.zeros((len(eps_vals), len(samp_vals)))\n",
        "    ss = StandardScaler()\n",
        "    df_scaled = ss.fit_transform(df)\n",
        "    maximum = 0\n",
        "    max_i = None\n",
        "    max_j = None\n",
        "    for i, e in enumerate(eps_vals):\n",
        "        for j, s in enumerate(samp_vals):\n",
        "            dbscan = DBSCAN(eps=e, min_samples=s)\n",
        "            dbscan.fit(df_scaled)\n",
        "            if len(set(dbscan.labels_)) > 2:\n",
        "                scores[i][j] = silhouette_score(df_scaled, dbscan.labels_)\n",
        "            if scores[i][j] > maximum:\n",
        "                maximum = scores[i][j]\n",
        "                max_i = i\n",
        "                max_j = j\n",
        "    best_eps = eps_vals[max_i]\n",
        "    best_samp = samp_vals[max_j]\n",
        "    dbscan = DBSCAN(eps=best_eps, min_samples=best_samp)\n",
        "    dbscan.fit(df_scaled)\n",
        "    print(f'best eps: {best_eps}')\n",
        "    print(f'best min samples: {best_samp}')\n",
        "    print(f'best n-clusters: {len(set(dbscan.labels_)) - 1}')\n",
        "    print(f'best silhouette score: {silhouette_score(df_scaled, dbscan.labels_)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EflFkE5xTBLx"
      },
      "source": [
        "# c l e a n i n g  &  E D A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTOzWx8202fQ"
      },
      "source": [
        "#json to a dataframe\n",
        "import json\n",
        "\n",
        "def parse_data(file):\n",
        "    for l in open(file,'r'):\n",
        "        yield json.loads(l)\n",
        "\n",
        "data = list(parse_data('data/Sarcasm_Headlines_Dataset.json'))\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.columns = ['link', 'headline', 'sarcastic']\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skp-oioCTE2l"
      },
      "source": [
        "#removing non_numeric from (very stubborn) column\n",
        "df['birth_year'] = df.birth_year.str.replace(r\"[a-zA-Z]\",'').replace(r'[^0-9]+', '')\n",
        "#or (use both for extra removal POWER)\n",
        "df['birth_year'] = df['birth_year'].map(lambda x: ''.join([i for i in x if i.isdigit()]))\n",
        "#check for these empty quotes\n",
        "df.birth_year.min()\n",
        "#then drop 'em\n",
        "df = df[df.birth_year != '']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFqEbbE9848-"
      },
      "source": [
        "#some examples of exploring\n",
        "df[df['sex_m_f'] == 'male']['Survived'].value_counts(normalize=True)\n",
        "df.loc[df['Name'].str.contains('Capt. Edward')]\n",
        "df[df['Survived'] == 0].sort_values(['Fare']).tail()\n",
        "df[df['gender'] == 2]['trip_duration'].describe()\n",
        "\n",
        "df_viz[(df_viz[\"Neighborhood\"]==\"NoRidge\") | (df_viz[\"Yr Sold\"]==2007)]\n",
        "df_viz[(df_viz[\"Neighborhood\"]==\"NoRidge\") | (df_viz[\"Yr Sold\"]==2007)].SalePrice.mean()\n",
        "\n",
        "filter_qual = df_train_2[((df_train_2.SalePrice >= 200000) & (df_train_2.quality <= 10))].index\n",
        "df_train_2 = df_train_2.drop(filter_qual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_MdSh-QhHBf"
      },
      "source": [
        "#counting values and adding a column of sum\n",
        "count = lambda l1,l2: sum([1 for x in l1 if x in l2])\n",
        "df['count_punct'] = df.STATUS.apply(lambda s: count(s, string.punctuation))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7oHLAcGTE9i"
      },
      "source": [
        "#the monster filter of all filters\n",
        "df = df[df.quantity != 0]\n",
        "#string 'em\n",
        "df = df[(df.entitytype == 0) | (df.entitytype == 1) | (df.entitytype == 2) | (df.entitytype == 3)]\n",
        "#binary class with a condition\n",
        "df['smoking_status'] = np.where(((df['smoking_status'] == 'smokes') | (df['smoking_status'] == 'formerly smoked')), 1, 0)\n",
        "#removing duplicate columns\n",
        "df = df.loc[:,~df.columns.duplicated()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrWlpSs6idkQ"
      },
      "source": [
        "#columns of total text length\n",
        "df['status_length'] = [len(i) for i in df['STATUS']]\n",
        "#column of word count\n",
        "df['status_word_count'] = [len(i.split()) for i in df['STATUS']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list of specific column names\n",
        "list(df.columns[[2, 3]])"
      ],
      "metadata": {
        "id": "V4BxBsv1KEFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnkW0e_p7xDy"
      },
      "source": [
        "#pivot table to sparse matrix; lesson 8.04 recommenders\n",
        "from scipy import sparse\n",
        "import sys\n",
        "\n",
        "piv_df = pd.pivot_table(data = full_df, index = 'title', columns = 'userId', values = 'rating')\n",
        "#fill the NaN with zero then sparse to save memory\n",
        "sparse_df = sparse.csc_matrix(piv_df.fillna(0))\n",
        "#getting the distances\n",
        "pairwise_distances(sparse_df, metric = 'cosine')\n",
        "#back into a df #for cosine 0 = itself\n",
        "rec_df = pd.DataFrame(recommender, columns = piv_df.index, index = piv_df.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgaqCNxO857Q"
      },
      "source": [
        "# stubborn timeseries convert\n",
        "df[date_cols] = df[date_cols].apply(pd.to_datetime, errors = 'coerce')\n",
        "#summing by year (time series?)\n",
        "df = df.groupby(df.index).sum()\n",
        "# not time series\n",
        "df.groupby(by = ['periodyear', 'period']).sum()\n",
        "# making a new timeseries col\n",
        "good_df['time_op'] = [pd.to_datetime('06/15/2021') - i for i in good_df['entityformdate']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LTsBbBpm9pR"
      },
      "source": [
        "#new column thing - very good one\n",
        "esol_data[\"n_Atoms\"] = esol_data['ROMol'].map(lambda x: x.GetNumAtoms())\n",
        "esol_data.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsB2RppHjjPR"
      },
      "source": [
        "#value counterator\n",
        "for i in ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']:\n",
        "    print(df[i].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88yqXjxzkPKk"
      },
      "source": [
        "#outlier remover\n",
        "### Thanks for the function https://www.kaggle.com/ankitak46\n",
        "\n",
        "def remove_outliers(data):\n",
        "    arr=[]\n",
        "    #print(max(list(data)))\n",
        "    q1=np.percentile(data,25)\n",
        "    q3=np.percentile(data,75)\n",
        "    iqr=q3-q1\n",
        "    mi=q1-(1.5*iqr)\n",
        "    ma=q3+(1.5*iqr)\n",
        "    #print(mi,ma)\n",
        "    for i in list(data):\n",
        "        if i<mi:\n",
        "            i=mi\n",
        "            arr.append(i)\n",
        "        elif i>ma:\n",
        "            i=ma\n",
        "            arr.append(i)\n",
        "        else:\n",
        "            arr.append(i)\n",
        "    #print(max(arr))\n",
        "    return arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHmWihCXchM1"
      },
      "source": [
        "#another method of outliers\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html#sklearn.ensemble.IsolationForest\n",
        "from sklearn.ensemble import IsolationForest\n",
        "iso = IsolationForest(n_estimators = 1000)\n",
        "X_prep = mct.fit_transform(X)\n",
        "X_outs = pd.Series(iso.fit_predict(X_prep))\n",
        "X_outs.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TTblBfBnXIK"
      },
      "source": [
        "#colinearity test\n",
        "# Function to calculate VIF\n",
        "#https://www.analyticsvidhya.com/blog/2020/03/one-hot-encoding-vs-label-encoding-using-scikit-learn/\n",
        "def calculate_vif(data):\n",
        "    vif_df = pd.DataFrame(columns = ['Var', 'Vif'])\n",
        "    x_var_names = data.columns\n",
        "    for i in range(0, x_var_names.shape[0]):\n",
        "        y = data[x_var_names[i]]\n",
        "        x = data[x_var_names.drop([x_var_names[i]])]\n",
        "        r_squared = sm.OLS(y,x).fit().rsquared\n",
        "        vif = round(1/(1-r_squared),2)\n",
        "        vif_df.loc[i] = [x_var_names[i], vif]\n",
        "    return vif_df.sort_values(by = 'Vif', axis = 0, ascending=False, inplace=False)\n",
        "\n",
        "X=df.drop(['Salary'],axis=1)\n",
        "calculate_vif(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2C8m6IpA5m-"
      },
      "source": [
        "#making binary classes\n",
        "y = np.where(df['subreddit'] == 'AskALiberal', 0, 1)\n",
        "\n",
        "#making multiclass classes\n",
        "df['variable'].replace(to_replace = 'antibiotic efflux',\n",
        "                                    value = 0, inplace=True)\n",
        "\n",
        "df['variable'].replace(to_replace = 'antibiotic inactivation',\n",
        "                                    value = 1, inplace=True)\n",
        "\n",
        "df['variable'].replace(to_replace = 'antibiotic target alteration',\n",
        "                                    value = 2, inplace=True)\n",
        "\n",
        "df['variable'].replace(to_replace = 'antibiotic target replacement',\n",
        "                                    value = 3, inplace=True)\n",
        "\n",
        "df['variable'].replace(to_replace = 'antibiotic target protection',\n",
        "                                    value = 4, inplace=True)\n",
        "\n",
        "df['variable'].replace(to_replace = 'reduced permeability to antibiotic',\n",
        "                                    value = 5, inplace=True)\n",
        "#or define variable first\n",
        "y = df['variable']\n",
        "y = y.replace({\n",
        "    'Adelie': 0,\n",
        "    'Gentoo': 1,\n",
        "    'Chinstrap': 2\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh-bODvj9kkR"
      },
      "source": [
        "# drops a row if all features missing\n",
        "penguins.dropna(subset = feature_cols, how = 'all', inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayddomw2_XfE"
      },
      "source": [
        "# some lambda things\n",
        "\n",
        "# basic; adds three to every row values\n",
        "test['age'] = test['age'].apply(lambda x: x + 3)\n",
        "\n",
        "# filtering\n",
        "list(filter(lambda x: x>18, test['age']))\n",
        "\n",
        "# new category column with conditional\n",
        "test['category'] = test['age'].apply(lambda x: 'Adult' if x >= 18 else 'Child')\n",
        "\n",
        "# doin a math with different column conditional\n",
        "df['Price'] = df['Price'].apply(lambda x: (x * 0.22) if df.loc('Currency' == 'PLN') else x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lots of column renames\n",
        "\n",
        "old_cols = [i for i in df.columns]\n",
        "\n",
        "new_cols = ['state', 'delete1', 'county', \"county_descr\", \"university\", \"major\",\n",
        "           \"delete2\", \"type1\", \"type2\", \"latitude\", \"longitude\", \"delete3\", \"delete4\"]\n",
        "\n",
        "rename_col_dict = {old_cols[i] : new_cols[i] for i in range(len(old_cols))}\n",
        "\n",
        "df.loc[-1] = df.columns.values\n",
        "df.sort_index(inplace = True)\n",
        "df.reset_index(drop = True, inplace = True)\n",
        "\n",
        "df.rename(columns = rename_col_dict, inplace = True)\n",
        "\n",
        "df.drop(columns = ['delete1', 'delete2', 'delete3', 'delete4'], inplace = True)"
      ],
      "metadata": {
        "id": "c_R6yloHY809"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merging columns and keeping none null value\n",
        "region_cols = [i for i in df.iloc[:, 7:27]]\n",
        "df.fillna(\" \", inplace = True)\n",
        "df['region'] = df[region_cols].agg(''.join, axis=1).drop(columns = region_cols)\n",
        "df.drop(columns = region_cols, inplace = True)"
      ],
      "metadata": {
        "id": "kqWLwwUzfmhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlOH1NNRU3v9"
      },
      "source": [
        "# *n u m p y / m a t h s*\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7xVAvuRU3Al"
      },
      "source": [
        "#prediction accuracy\n",
        "np.count_nonzero((predictions == 1) & (y == 1) | (predictions == 0) & (y == 0)) / np.size(y)\n",
        "#making binary\n",
        "y = np.where(df['subreddit'] == 'AskALiberal', 0, 1)\n",
        "#see numpy ladders 1-3 for more"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtT7fqpxUwWg"
      },
      "source": [
        "num_list = [1, 3, 2, 5, 4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qcLLY-fVITg"
      },
      "source": [
        "num_list.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS9seaHAUzvp",
        "outputId": "f2992a51-8a2a-4d39-c867-13aab2b00721"
      },
      "source": [
        "print(num_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep4OMzerU2B7"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}